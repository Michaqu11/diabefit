{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 1. WCZYTYWANIE DANYCH ====\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Michał._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "\n",
    "# Konwersja daty na format datetime\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Usuwamy błędne daty\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "\n",
    "# ✅ Łączymy dane z dwóch kolumn (Historic + Scan)\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "\n",
    "# Zmieniamy nazwę kolumny i wybieramy kluczowe kolumny\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "# Przetwarzanie danych JSON\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "# Tworzymy DataFrame z JSON\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Połączone dane:\n",
      "   glucose  insulin    WW       hour  glucose_diff_max  glucose_diff_min   \n",
      "0      156      6.1  6.06   8.516667              27.0             -29.0  \\\n",
      "1      143      3.2  3.21  11.500000              27.0             -63.0   \n",
      "2      197      1.8  1.50   9.016667             -34.0            -124.0   \n",
      "3      124      5.0  5.03  23.600000              80.0               8.0   \n",
      "4      152      4.0  5.75  19.800000              51.0              -3.0   \n",
      "5      149      2.0  1.14   8.183333              35.0               0.0   \n",
      "6      129      3.1  3.12  10.550000              55.0             -27.0   \n",
      "7      112      3.0  3.00  12.833333               8.0             -33.0   \n",
      "8      119      1.1  1.14  17.366667              20.0             -12.0   \n",
      "9      170      4.5  5.06  20.016667              -9.0             -56.0   \n",
      "\n",
      "   total_dose  \n",
      "0        7.32  \n",
      "1        3.84  \n",
      "2        2.16  \n",
      "3        6.00  \n",
      "4        4.80  \n",
      "5        2.40  \n",
      "6        3.72  \n",
      "7        3.60  \n",
      "8        1.32  \n",
      "9        5.40  \n"
     ]
    }
   ],
   "source": [
    "# ==== Dopasowywanie danych ====\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for index, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) & (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        total_dose = row['insulin'] * 1.2\n",
    "\n",
    "        merged_data.append([\n",
    "            row['glucose'], row['insulin'], WW, hour,\n",
    "            glucose_diff_max, glucose_diff_min, total_dose\n",
    "        ])\n",
    "\n",
    "# ✅ Print sprawdzający połączone dane\n",
    "print(\"\\n✅ Połączone dane:\")\n",
    "print(pd.DataFrame(merged_data, columns=['glucose', 'insulin', 'WW', 'hour', 'glucose_diff_max', 'glucose_diff_min', 'total_dose']).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy DataFrame z połączonych danych\n",
    "data = pd.DataFrame(merged_data, columns=[\n",
    "    'glucose', 'insulin', 'WW', 'hour',\n",
    "    'glucose_diff_max', 'glucose_diff_min', 'total_dose'\n",
    "])\n",
    "\n",
    "# ==== Skalowanie danych ====\n",
    "scalers = {}\n",
    "for col in data.columns:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# ==== Przygotowanie sekwencji dla GRU ====\n",
    "sequence_length = 20\n",
    "X, y = [], []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    X.append(data.iloc[i:i + sequence_length].values)\n",
    "    y.append(data['total_dose'].iloc[i + sequence_length])\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.7745\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5992 \n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4243 \n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3309 \n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3541 \n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3294 \n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4477 \n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3079 \n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3437 \n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2984 \n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3415 \n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3501 \n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3267 \n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3817 \n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3955 \n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3181 \n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4201 \n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2942 \n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2930 \n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2740 \n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3783 \n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3098 \n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2864 \n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3013 \n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3043 \n"
     ]
    }
   ],
   "source": [
    "# ==== Definicja modelu GRU ====\n",
    "model = Sequential()\n",
    "model.add(GRU(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2]), kernel_regularizer=l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GRU(64, kernel_regularizer=l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# ✅ Kompilacja modelu\n",
    "model.compile(optimizer='adam', loss=Huber())\n",
    "\n",
    "# ✅ Early stopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# ==== Trenowanie modelu ====\n",
    "history = model.fit(X, y, epochs=100, batch_size=16, callbacks=[early_stopping])\n",
    "\n",
    "# Zapis modelu\n",
    "model.save('insulin_predictor.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "🔥 Proponowana dawka: 4.43 jednostek\n"
     ]
    }
   ],
   "source": [
    "# ==== TESTY ====\n",
    "test_input = pd.DataFrame([[150, 5, 5, 9.5, 20, -10, 0]], columns=data.columns)\n",
    "\n",
    "# ✅ Skalowanie testów zgodnie z zakresem danych treningowych\n",
    "for col in test_input.columns:\n",
    "    test_input[col] = scalers[col].transform(test_input[[col]])\n",
    "\n",
    "# ✅ Ustawiamy sekwencję testową o długości 20\n",
    "test_sequence = np.zeros((1, sequence_length, test_input.shape[1]))\n",
    "test_sequence[0, -1, :] = test_input.iloc[0].values\n",
    "\n",
    "# ✅ Predykcja\n",
    "predicted_dose = model.predict(test_sequence)[0][0]\n",
    "predicted_dose = scalers['total_dose'].inverse_transform([[predicted_dose]])[0][0]\n",
    "predicted_dose = max(0.5, min(predicted_dose, 15))\n",
    "\n",
    "# ✅ Wynik predykcji\n",
    "print(f\"\\n🔥 Proponowana dawka: {predicted_dose:.2f} jednostek\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
