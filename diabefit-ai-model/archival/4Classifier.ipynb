{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         1\n",
      "          -1       0.00      0.00      0.00         2\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.40      0.80      0.53         5\n",
      "           2       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.58        19\n",
      "   macro avg       0.43      0.48      0.44        19\n",
      "weighted avg       0.55      0.58      0.54        19\n",
      "\n",
      "üî• Dawka za ma≈Ça ‚Üí Zwiƒôksz dawkƒô insuliny!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Micha≈Ç._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)\n",
    "\n",
    "# ==== Dopasowywanie danych ====\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for _, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) &\n",
    "                                  (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        # ‚úÖ Klasyfikacja dawek\n",
    "        if glucose_max > 180:\n",
    "            dose_feedback = 2  # Znacznie za ma≈Ça dawka\n",
    "        elif glucose_max > 140:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif glucose_min < 80:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif glucose_min < 100:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        else:\n",
    "            dose_feedback = 0  # OK\n",
    "\n",
    "        merged_data.append([\n",
    "            row['glucose'], row['insulin'], WW, hour,\n",
    "            glucose_diff_max, glucose_diff_min, dose_feedback\n",
    "        ])\n",
    "\n",
    "data = pd.DataFrame(merged_data, columns=[\n",
    "    'glucose', 'insulin', 'WW', 'hour', 'glucose_diff_max', 'glucose_diff_min', 'dose_feedback'\n",
    "])\n",
    "\n",
    "# ==== Skalowanie danych ====\n",
    "scalers = {}\n",
    "for col in data.columns[:-1]:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# ==== Klasyfikacja ====\n",
    "X = data.iloc[:, :-1]\n",
    "y = data['dose_feedback']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‚úÖ Model RandomForest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Ocena modelu\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ==== TESTY ====\n",
    "test_input = pd.DataFrame([[150, 20, 5, 9.5, 20, -10]], columns=data.columns[:-1])\n",
    "for col in test_input.columns:\n",
    "    test_input[col] = scalers[col].transform(test_input[[col]])\n",
    "\n",
    "predicted_class = model.predict(test_input)[0]\n",
    "\n",
    "# ‚úÖ Interpretacja wyniku\n",
    "if predicted_class == 2:\n",
    "    print(\"üî• Dawka znacznie za ma≈Ça ‚Üí Zwiƒôksz dawkƒô insuliny!\")\n",
    "elif predicted_class == 1:\n",
    "    print(\"üî• Dawka za ma≈Ça ‚Üí Zwiƒôksz dawkƒô insuliny!\")\n",
    "elif predicted_class == -2:\n",
    "    print(\"‚ùÑÔ∏è Dawka znacznie za du≈ºa ‚Üí Zmniejsz dawkƒô insuliny!\")\n",
    "elif predicted_class == -1:\n",
    "    print(\"‚ùÑÔ∏è Dawka za du≈ºa ‚Üí Zmniejsz dawkƒô insuliny!\")\n",
    "else:\n",
    "    print(\"‚úÖ Dawka OK ‚Üí Kontynuuj w tej samej dawce.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùÑÔ∏è Dawka za du≈ºa ‚Üí Zmniejsz dawkƒô insuliny!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       1.00      1.00      1.00         3\n",
      "          -1       1.00      1.00      1.00         9\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       1.00      1.00      1.00        32\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        91\n",
      "   macro avg       1.00      1.00      1.00        91\n",
      "weighted avg       1.00      1.00      1.00        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Micha≈Ç._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "\n",
    "# Konwersja daty na format datetime\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Usuwamy b≈Çƒôdne daty\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "\n",
    "# ‚úÖ ≈ÅƒÖczymy dane z dw√≥ch kolumn (Historic + Scan)\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "# Przetwarzanie danych JSON\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)\n",
    "\n",
    "# ==== Dopasowywanie danych ====\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for index, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) & (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        # ‚úÖ Nowa logika klasyfikacji\n",
    "        if (80 <= row['glucose'] + glucose_diff_max <= 150) and (80 <= row['glucose'] + glucose_diff_min <= 150):\n",
    "            dose_feedback = 0  # OK\n",
    "        elif abs(glucose_diff_max) <= 30 and abs(glucose_diff_min) <= 30:\n",
    "            dose_feedback = 0  # OK\n",
    "        elif glucose_diff_max > 100:\n",
    "            dose_feedback = 2  # Znacznie za ma≈Ça dawka\n",
    "        elif glucose_diff_max > 50:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif glucose_diff_min < -100:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif glucose_diff_min < -50:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        else:\n",
    "            dose_feedback = 0\n",
    "\n",
    "        merged_data.append([\n",
    "            row['glucose'], row['insulin'], WW, hour,\n",
    "            glucose_diff_max, glucose_diff_min, dose_feedback\n",
    "        ])\n",
    "\n",
    "# Tworzymy DataFrame z po≈ÇƒÖczonych danych\n",
    "data = pd.DataFrame(merged_data, columns=[\n",
    "    'glucose', 'insulin', 'WW', 'hour',\n",
    "    'glucose_diff_max', 'glucose_diff_min', 'dose_feedback'\n",
    "])\n",
    "\n",
    "# ‚úÖ Osobne skalery dla ka≈ºdej zmiennej ‚Üí StandardScaler\n",
    "scalers = {}\n",
    "for col in data.columns[:-1]:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# ‚úÖ Klasyfikacja z RandomForest\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data['dose_feedback'].values\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# ==== TESTY ====\n",
    "test_input = pd.DataFrame([[150, 5, 5, 9.5, 30, -70]], columns=data.columns[:-1])\n",
    "\n",
    "# ‚úÖ Skalowanie test√≥w zgodnie z zakresem danych treningowych\n",
    "for col in test_input.columns:\n",
    "    test_input[col] = scalers[col].transform(test_input[[col]])\n",
    "\n",
    "# ‚úÖ Predykcja\n",
    "predicted_class = clf.predict(test_input)[0]\n",
    "\n",
    "# ‚úÖ Interpretacja wyniku\n",
    "if predicted_class == 2:\n",
    "    print(\"üî• Dawka znacznie za ma≈Ça ‚Üí Zwiƒôksz dawkƒô insuliny!\")\n",
    "elif predicted_class == 1:\n",
    "    print(\"üî• Dawka za ma≈Ça ‚Üí Zwiƒôksz dawkƒô insuliny!\")\n",
    "elif predicted_class == -2:\n",
    "    print(\"‚ùÑÔ∏è Dawka znacznie za du≈ºa ‚Üí Zmniejsz dawkƒô insuliny!\")\n",
    "elif predicted_class == -1:\n",
    "    print(\"‚ùÑÔ∏è Dawka za du≈ºa ‚Üí Zmniejsz dawkƒô insuliny!\")\n",
    "else:\n",
    "    print(\"‚úÖ Dawka OK ‚Üí Kontynuuj w tej samej dawce.\")\n",
    "\n",
    "# ‚úÖ Raport z klasyfikacji\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: [150, 5, 5, 9.5, 1, 5] -> Klasyfikacja: 1\n",
      "Test 2: [100, 5, 3, 12.0, 0, 1.7] -> Klasyfikacja: 1\n",
      "Test 3: [200, 15, 6, 18.5, 2, 2.5] -> Klasyfikacja: 0\n",
      "Test 4: [90, 2, 2, 22.0, 3, 1.0] -> Klasyfikacja: 2\n",
      "Test 5: [180, 25, 5, 8.0, 1, 5.0] -> Klasyfikacja: 0\n",
      "Test 6: [140, 6, 4, 14.0, 2, 1.5] -> Klasyfikacja: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Micha≈Ç._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "\n",
    "# Konwersja daty na format datetime\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Usuwamy b≈Çƒôdne daty\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "\n",
    "# ‚úÖ ≈ÅƒÖczymy dane z dw√≥ch kolumn (Historic + Scan)\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "\n",
    "# Usuwamy przypadki, gdzie poziom glukozy wynosi 0\n",
    "glucose_data = glucose_data[glucose_data['glucose'] > 0]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "# Przetwarzanie danych JSON\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)\n",
    "\n",
    "# ==== Dopasowywanie danych ====\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for index, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) & (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "\n",
    "        if 6 <= meal_time.hour < 12:\n",
    "            part_of_day = 0  # Poranek\n",
    "        elif 12 <= meal_time.hour < 18:\n",
    "            part_of_day = 1  # Popo≈Çudnie\n",
    "        elif 18 <= meal_time.hour < 24:\n",
    "            part_of_day = 2  # Wiecz√≥r\n",
    "        else:\n",
    "            part_of_day = 3  # Noc\n",
    "\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        # ‚úÖ Ulepszona logika klasyfikacji\n",
    "        if insulin_per_WW > 3.0:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif insulin_per_WW > 2.5:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        elif (80 <= row['glucose'] + glucose_diff_max <= 150) and (80 <= row['glucose'] + glucose_diff_min <= 150):\n",
    "            dose_feedback = 0  # OK\n",
    "        elif glucose_diff_max > 150:\n",
    "            dose_feedback = 2  # Znacznie za ma≈Ça dawka\n",
    "        elif glucose_diff_max > 75:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif glucose_diff_min < -150:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif glucose_diff_min < -75:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        else:\n",
    "            dose_feedback = 0\n",
    "\n",
    "        merged_data.append([\n",
    "            row['glucose'], row['insulin'], WW, hour,\n",
    "            part_of_day, insulin_per_WW, dose_feedback\n",
    "        ])\n",
    "\n",
    "# Tworzymy DataFrame z po≈ÇƒÖczonych danych\n",
    "data = pd.DataFrame(merged_data, columns=[\n",
    "    'glucose', 'insulin', 'WW', 'hour', 'part_of_day', 'insulin_per_WW', 'dose_feedback'\n",
    "])\n",
    "\n",
    "# ‚úÖ Osobne skalery dla ka≈ºdej zmiennej ‚Üí StandardScaler\n",
    "scalers = {}\n",
    "for col in data.columns[:-1]:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# ‚úÖ Klasyfikacja z RandomForest\n",
    "X = data[['glucose', 'insulin', 'WW', 'hour', 'part_of_day', 'insulin_per_WW']].values\n",
    "y = data['dose_feedback'].values\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700, max_depth=15, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# ==== TESTY ====\n",
    "test_cases = [\n",
    "    [150, 5, 5, 9.5, 1, 5],\n",
    "    [100, 5, 3, 12.0, 0, 1.7],\n",
    "    [200, 15, 6, 18.5, 2, 2.5],\n",
    "    [90, 2, 2, 22.0, 3, 1.0],\n",
    "    [180, 25, 5, 8.0, 1, 5.0],\n",
    "    [140, 6, 4, 14.0, 2, 1.5]\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(test_cases, columns=['glucose', 'insulin', 'WW', 'hour', 'part_of_day', 'insulin_per_WW'])\n",
    "for col in test_df.columns:\n",
    "    test_df[col] = scalers[col].transform(test_df[[col]])\n",
    "\n",
    "predictions = clf.predict(test_df)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Test {i+1}: {test_cases[i]} -> Klasyfikacja: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    glucose  insulin    WW       hour  part_of_day  dose_feedback   \n",
      "0       156      6.1  6.06   8.516667            0              0  \\\n",
      "1       143      3.2  3.21  11.500000            0              0   \n",
      "2       197      1.8  1.50   9.016667            0             -1   \n",
      "3       124      5.0  5.03  23.600000            2              1   \n",
      "4       152      4.0  5.75  19.800000            2              1   \n",
      "..      ...      ...   ...        ...          ...            ...   \n",
      "86      161      2.2  1.04   8.883333            0              0   \n",
      "87      123      3.5  3.50  11.200000            0              0   \n",
      "88      109      3.5  3.00  13.083333            1              0   \n",
      "89      170      2.5  1.50   9.850000            0              0   \n",
      "90      150      9.0  9.69  16.516667            1              0   \n",
      "\n",
      "                                       glucose_values  \n",
      "0   [127.0, 129.0, 134.0, 136.0, 132.0, 135.0, 136...  \n",
      "1   [122.0, 119.0, 108.0, 102.0, 98.0, 81.0, 97.0,...  \n",
      "2   [163.0, 158.0, 152.0, 150.0, 142.0, 141.0, 129...  \n",
      "3   [132.0, 135.0, 146.0, 152.0, 150.0, 152.0, 170...  \n",
      "4   [151.0, 149.0, 149.0, 155.0, 156.0, 169.0, 194...  \n",
      "..                                                ...  \n",
      "86  [165.0, 171.0, 167.0, 165.0, 156.0, 140.0, 130.0]  \n",
      "87  [120.0, 116.0, 125.0, 123.0, 127.0, 118.0, 117...  \n",
      "88  [113.0, 104.0, 101.0, 97.0, 79.0, 100.0, 126.0...  \n",
      "89  [165.0, 161.0, 181.0, 183.0, 195.0, 196.0, 193...  \n",
      "90  [190.0, 189.0, 181.0, 175.0, 178.0, 192.0, 187...  \n",
      "\n",
      "[91 rows x 7 columns]\n",
      "Test 1: [150, 2, 5, 9.5, 1] -> Klasyfikacja: 0\n",
      "Test 2: [100, 5, 3, 12.0, 0] -> Klasyfikacja: 1\n",
      "Test 3: [200, 15, 6, 18.5, 2] -> Klasyfikacja: 0\n",
      "Test 4: [90, 2, 2, 22.0, 3] -> Klasyfikacja: 2\n",
      "Test 5: [180, 25, 5, 8.0, 1] -> Klasyfikacja: 0\n",
      "Test 6: [140, 6, 4, 14.0, 2] -> Klasyfikacja: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Micha≈Ç._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "\n",
    "# Konwersja daty na format datetime\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Usuwamy b≈Çƒôdne daty\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "\n",
    "# ‚úÖ ≈ÅƒÖczymy dane z dw√≥ch kolumn (Historic + Scan)\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "\n",
    "# Usuwamy przypadki, gdzie poziom glukozy wynosi 0\n",
    "glucose_data = glucose_data[glucose_data['glucose'] > 0]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "# Przetwarzanie danych JSON\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)\n",
    "\n",
    "# ==== Dopasowywanie danych ====\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for index, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) & (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "        glucose_values = glucose_window['glucose'].values.tolist()\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "\n",
    "        if 6 <= meal_time.hour < 12:\n",
    "            part_of_day = 0  # Poranek\n",
    "        elif 12 <= meal_time.hour < 18:\n",
    "            part_of_day = 1  # Popo≈Çudnie\n",
    "        elif 18 <= meal_time.hour < 24:\n",
    "            part_of_day = 2  # Wiecz√≥r\n",
    "        else:\n",
    "            part_of_day = 3  # Noc\n",
    "\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        # ‚úÖ Nowa logika klasyfikacji\n",
    "        if (80 <= row['glucose'] + glucose_diff_max <= 150) and (80 <= row['glucose'] + glucose_diff_min <= 150):\n",
    "            dose_feedback = 0  # OK\n",
    "        elif row['glucose'] > 150 and glucose_diff_max > 30:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif row['glucose'] < 80 and glucose_diff_min < -30:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        elif glucose_diff_max > 150:\n",
    "            dose_feedback = 2  # Znacznie za ma≈Ça dawka\n",
    "        elif glucose_diff_max > 75:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif glucose_diff_min < -150:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif glucose_diff_min < -75:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        else:\n",
    "            dose_feedback = 0\n",
    "\n",
    "        merged_data.append([\n",
    "            row['glucose'], row['insulin'], WW, hour,\n",
    "            part_of_day, dose_feedback, glucose_values\n",
    "        ])\n",
    "\n",
    "# Tworzymy DataFrame z po≈ÇƒÖczonych danych\n",
    "data = pd.DataFrame(merged_data, columns=[\n",
    "    'glucose', 'insulin', 'WW', 'hour', 'part_of_day', 'dose_feedback', 'glucose_values'\n",
    "])\n",
    "\n",
    "print(data)\n",
    "\n",
    "# ‚úÖ Osobne skalery dla ka≈ºdej zmiennej ‚Üí StandardScaler\n",
    "scalers = {}\n",
    "for col in data.columns[:-2]:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# ‚úÖ Klasyfikacja z RandomForest\n",
    "X = data[['glucose', 'insulin', 'WW', 'hour', 'part_of_day']].values\n",
    "y = data['dose_feedback'].values\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700, max_depth=15, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# ==== TESTY ====\n",
    "test_cases = [\n",
    "    [150, 2, 5, 9.5, 1],\n",
    "    [100, 5, 3, 12.0, 0],\n",
    "    [200, 15, 6, 18.5, 2],\n",
    "    [90, 2, 2, 22.0, 3],\n",
    "    [180, 25, 5, 8.0, 1],\n",
    "    [140, 6, 4, 14.0, 2]\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(test_cases, columns=['glucose', 'insulin', 'WW', 'hour', 'part_of_day'])\n",
    "for col in test_df.columns:\n",
    "    test_df[col] = scalers[col].transform(test_df[[col]])\n",
    "\n",
    "predictions = clf.predict(test_df)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Test {i+1}: {test_cases[i]} -> Klasyfikacja: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [00:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: [150, 2, 5, 9.5, 1] -> Klasyfikacja: -1\n",
      "Test 2: [100, 5, 3, 12.0, 0] -> Klasyfikacja: -1\n",
      "Test 3: [200, 15, 6, 18.5, 2] -> Klasyfikacja: -1\n",
      "Test 4: [90, 2, 2, 22.0, 3] -> Klasyfikacja: 1\n",
      "Test 5: [180, 25, 5, 8.0, 1] -> Klasyfikacja: -1\n",
      "Test 6: [140, 6, 4, 14.0, 2] -> Klasyfikacja: -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# ==== Wczytywanie pliku CSV ====\n",
    "glucose_data = pd.read_csv('Micha≈Ç._glucose_8-3-2025.csv', skiprows=1, delimiter=',', low_memory=False)\n",
    "\n",
    "glucose_data['Device Timestamp'] = pd.to_datetime(glucose_data['Device Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "glucose_data = glucose_data.dropna(subset=['Device Timestamp'])\n",
    "\n",
    "glucose_data['glucose'] = glucose_data['Historic Glucose mg/dL'].combine_first(glucose_data['Scan Glucose mg/dL'])\n",
    "glucose_data = glucose_data.rename(columns={'Device Timestamp': 'date'})\n",
    "glucose_data = glucose_data[['date', 'glucose']]\n",
    "glucose_data = glucose_data[glucose_data['glucose'] > 0]\n",
    "\n",
    "# ==== Wczytywanie pliku JSON ====\n",
    "with open('data (6).json', 'r') as f:\n",
    "    meals_data = json.load(f)\n",
    "\n",
    "processed_data = []\n",
    "for user_id, records in meals_data.items():\n",
    "    for record in records:\n",
    "        calculator = record.get('calculatorData')\n",
    "        if calculator:\n",
    "            glucose = calculator.get('glucose')\n",
    "            insulin = calculator.get('units', {}).get('short')\n",
    "            date = pd.to_datetime(calculator.get('date'), errors='coerce')\n",
    "            carbs = sum(meal.get('carbs', 0) for meal in record.get('meals', []))\n",
    "            processed_data.append([date, glucose, insulin, carbs])\n",
    "\n",
    "meals_df = pd.DataFrame(processed_data, columns=['date', 'glucose', 'insulin', 'carbs'])\n",
    "meals_df['date'] = meals_df['date'].dt.tz_convert(None)\n",
    "\n",
    "glucose_data = glucose_data.sort_values('date').reset_index(drop=True)\n",
    "meals_df = meals_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "merged_data = []\n",
    "for index, row in meals_df.iterrows():\n",
    "    meal_time = row['date']\n",
    "    glucose_window = glucose_data[(glucose_data['date'] >= meal_time + pd.Timedelta(hours=1)) & (glucose_data['date'] <= meal_time + pd.Timedelta(hours=2.5))]\n",
    "\n",
    "    if not glucose_window.empty:\n",
    "        glucose_max = np.nanmax(glucose_window['glucose'].values)\n",
    "        glucose_min = np.nanmin(glucose_window['glucose'].values)\n",
    "\n",
    "        WW = row['carbs'] / 10\n",
    "        insulin_per_WW = row['insulin'] / WW if WW > 0 else 0\n",
    "        hour = meal_time.hour + meal_time.minute / 60\n",
    "        part_of_day = 0 if 6 <= meal_time.hour < 12 else 1 if 12 <= meal_time.hour < 18 else 2 if 18 <= meal_time.hour < 24 else 3\n",
    "        glucose_diff_max = glucose_max - row['glucose']\n",
    "        glucose_diff_min = glucose_min - row['glucose']\n",
    "\n",
    "        if (80 <= row['glucose'] + glucose_diff_max <= 150) and (80 <= row['glucose'] + glucose_diff_min <= 150):\n",
    "            dose_feedback = 0  # OK\n",
    "        elif glucose_diff_max > 150:\n",
    "            dose_feedback = 2  # Znacznie za ma≈Ça dawka\n",
    "        elif glucose_diff_max > 75:\n",
    "            dose_feedback = 1  # Za ma≈Ça dawka\n",
    "        elif glucose_diff_min < -150:\n",
    "            dose_feedback = -2  # Znacznie za du≈ºa dawka\n",
    "        elif glucose_diff_min < -75:\n",
    "            dose_feedback = -1  # Za du≈ºa dawka\n",
    "        else:\n",
    "            dose_feedback = 0\n",
    "\n",
    "        merged_data.append([row['glucose'], row['insulin'], WW, hour, part_of_day, dose_feedback])\n",
    "\n",
    "data = pd.DataFrame(merged_data, columns=['glucose', 'insulin', 'WW', 'hour', 'part_of_day', 'dose_feedback'])\n",
    "scalers = {}\n",
    "for col in data.columns[:-1]:\n",
    "    scaler = StandardScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "y = data['dose_feedback'].values + 2  # Przesuniƒôcie klas do zakresu [0, 1, 2, 3, 4]\n",
    "y = y - np.min(y)\n",
    "X = data[['glucose', 'insulin', 'WW', 'hour', 'part_of_day']].values\n",
    "\n",
    "clf = xgb.XGBClassifier(objective='multi:softmax', num_class=5, n_estimators=700, max_depth=15, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "clf.fit(X, y)\n",
    "\n",
    "test_cases = [\n",
    "    [150, 2, 5, 9.5, 1],\n",
    "    [100, 5, 3, 12.0, 0],\n",
    "    [200, 15, 6, 18.5, 2],\n",
    "    [90, 2, 2, 22.0, 3],\n",
    "    [180, 25, 5, 8.0, 1],\n",
    "    [140, 6, 4, 14.0, 2]\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(test_cases, columns=['glucose', 'insulin', 'WW', 'hour', 'part_of_day'])\n",
    "for col in test_df.columns:\n",
    "    test_df[col] = scalers[col].transform(test_df[[col]])\n",
    "\n",
    "predictions = clf.predict(test_df) - 2  # Powr√≥t do oryginalnych etykiet\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Test {i+1}: {test_cases[i]} -> Klasyfikacja: {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
